{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required packages\n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Getting current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Creating a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# joining the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "# creating (event_datafile_full.csv) file that will be used to insert data into the Apache Cassandra tables.\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# checking the number of rows in (event_datafile_new.csv) file.\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Apache Cassandra coding portion of the project. \n",
    "\n",
    "## The CSV file titled <font color=red>event_datafile_new.csv</font>, located within the current directory, is now ready to load data from. The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a connection to Apache Cassandra instance in the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a cluster and making a connection to an instance in the local machine\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "    # starting a session to make a connection and execute queries\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS project2\n",
    "    WITH REPLICATION = \n",
    "    {'class' : 'SimpleStrategy', 'replication_factor' : 1}\"\"\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('project2')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tables suitable for the following three questions of the data:\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding for the first query.\n",
    "#####    The coding goes like that:\n",
    "    1- creating the table in the first cell.\n",
    "    2- inserting the suitable data from event_datafile_new.csv file into the table in the second cell.\n",
    "    3- selecting data from the table to verify the correctness of the table and its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "# sessionId = 338, and itemInSession = 4\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_info_by_session \\\n",
    "            (sessionId int, \\\n",
    "             itemInSession int, \\\n",
    "             artist text, \\\n",
    "             song text, \\\n",
    "             length decimal, \\\n",
    "             PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Query_1 Description: \n",
    "In this query, we need information about the songs played using a specific session information. So, I used `sessionId` as the partition key and `itemInSession` as my clustering key. Each partition is uniquely identified by `sessionId` while `itemInSession` was used to uniquely identify the rows within a partition to sort the data by the value of `itemInSession`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "# Assigning the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO song_info_by_session (sessionId, itemInSession, artist, song, length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        # Assigning which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.3073\n"
     ]
    }
   ],
   "source": [
    "# The SELECT statement to verify the data was entered into the table\n",
    "\n",
    "query = \"SELECT artist, song, length \\\n",
    "         FROM song_info_by_session \\\n",
    "         WHERE sessionId = 338 AND itemInSession = 4\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(row.artist, row.song, row.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>length</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>itemInSession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.3073</td>\n",
       "      <td>338</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                             song    length  sessionId  \\\n",
       "444  Faithless  Music Matters (Mark Knight Dub)  495.3073        338   \n",
       "\n",
       "     itemInSession  \n",
       "444              4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to make sure the above result is correct, I'm going to get the result by subsetting a pandas dataframe.\n",
    "\n",
    "df = pd.read_csv('event_datafile_new.csv')\n",
    "df[(df.sessionId == 338) & (df.itemInSession == 4)][[\"artist\", \"song\", \"length\", \"sessionId\", \"itemInSession\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding for the second query.\n",
    "#####    The coding goes like that:\n",
    "    1- creating the table in the first cell.\n",
    "    2- inserting the suitable data from event_datafile_new.csv file into the table in the second cell.\n",
    "    3- selecting data from the table to verify the correctness of the table and its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "# for userid = 10, sessionid = 182\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_and_user_info_by_userid_and_session \\\n",
    "            (userId int, \\\n",
    "             sessionId int, \\\n",
    "             itemInSession int, \\\n",
    "             artist text, \\\n",
    "             song text, \\\n",
    "             firstName text, \\\n",
    "             lastName text, \\\n",
    "             PRIMARY KEY ((userId, sessionId), itemInSession))\" # including itemInSession as a clustring key just to sort by it\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Query_2 Description: \n",
    "In this query, we need information about the songs and the users who played them using a specific user_id and session information. So, I used both (`userId`, `sessionId`) as a composite partition key and `itemInSession` as a clustering key. Each partition is uniquely identified by the composite key (`userId`, `sessionId`) while `itemInSession` was used to uniquely identify the rows within each partition to sort the data by the value of `itemInSession`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "# Assigning the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO song_and_user_info_by_userid_and_session \\\n",
    "                    (userId, sessionId, itemInSession, artist, song, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        # Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone || Keep On Keepin' On || Sylvie || Cruz\n",
      "Three Drives || Greece 2000 || Sylvie || Cruz\n",
      "Sebastien Tellier || Kilometer || Sylvie || Cruz\n",
      "Lonnie Gordon || Catch You Baby (Steve Pitron & Max Sanna Radio Edit) || Sylvie || Cruz\n"
     ]
    }
   ],
   "source": [
    "# The SELECT statement to verify the data was entered into the table\n",
    "\n",
    "query = \"SELECT artist, song, firstName, lastName \\\n",
    "         FROM song_and_user_info_by_userid_and_session \\\n",
    "         WHERE userId = 10 AND sessionId = 182\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(row.artist, '||', row.song, '||', row.firstname, '||', row.lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist                                               song  \\\n",
       "4704   Down To The Bone                                 Keep On Keepin' On   \n",
       "4705       Three Drives                                        Greece 2000   \n",
       "4706  Sebastien Tellier                                          Kilometer   \n",
       "4707      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "     firstName lastName  \n",
       "4704    Sylvie     Cruz  \n",
       "4705    Sylvie     Cruz  \n",
       "4706    Sylvie     Cruz  \n",
       "4707    Sylvie     Cruz  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to make sure the above result is correct, I'm going to get the result by subsetting a pandas dataframe.\n",
    "\n",
    "df[(df.userId == 10) & (df.sessionId == 182)][[\"artist\", \"song\", \"firstName\", \"lastName\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding for the third query.\n",
    "#####    The coding goes like that:\n",
    "    1- creating the table in the first cell.\n",
    "    2- inserting the suitable data from event_datafile_new.csv file into the table in the second cell.\n",
    "    3- selecting data from the table to verify the correctness of the table and its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS username_by_song_title \\\n",
    "            (song text, \\\n",
    "             userId int, \\\n",
    "             firstName text, \\\n",
    "             lastName text, \\\n",
    "             PRIMARY KEY (song, userId))\" # I chose to include userId in the primary key assuming song title \n",
    "                                          # will not be unique in the dominant majority of our data and the users' names\n",
    "                                          # may not be unnique.\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)         \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Query_3 Description: \n",
    "In this query, we need information about the users using a specific song title. So, I used `song` as the partition key and `userId` as my clustering key. The choice of `userId` was meant because we expect many users to listen to the same song, which makes `song` alone inefficient as a unique key. Meanwhile, we can't guarantee the users' names to be unique so `userId` was the best choice. Each partition is uniquely identified by `song` while `userId` was used to uniquely identify the rows within a partition to sort the data by the value of `userId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "# The INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO username_by_song_title (song, userId, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        \n",
    "        # Assigning which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "# The SELECT statement to verify the data was entered into the table\n",
    "\n",
    "query = \"SELECT firstName, lastName \\\n",
    "         FROM username_by_song_title \\\n",
    "         WHERE song = 'All Hands Against His Own'\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print(row.firstname, row.lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>All Hands Against His Own</td>\n",
       "      <td>Tegan</td>\n",
       "      <td>Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5135</th>\n",
       "      <td>All Hands Against His Own</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>All Hands Against His Own</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>Lynch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           song   firstName lastName\n",
       "2792  All Hands Against His Own       Tegan   Levine\n",
       "5135  All Hands Against His Own        Sara  Johnson\n",
       "6298  All Hands Against His Own  Jacqueline    Lynch"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to make sure the above result is correct, I'm going to get the result by subsetting a pandas dataframe.\n",
    "\n",
    "df[df.song == 'All Hands Against His Own'][[\"song\", \"firstName\", \"lastName\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the tables so that the tables are updated each time the data files are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"DROP TABLE IF EXISTS song_info_by_session\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    \n",
    "query = \"DROP TABLE IF EXISTS song_and_user_info_by_userid_and_session\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    \n",
    "query = \"DROP TABLE IF EXISTS username_by_song_title\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
